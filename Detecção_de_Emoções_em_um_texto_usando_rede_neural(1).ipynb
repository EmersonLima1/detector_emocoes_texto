{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Importação de bibliotecas\n",
        "import pandas as pd  # Biblioteca para manipulação de dados\n",
        "# Baixa o recurso 'stopwords' se não estiver disponível\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords  # Biblioteca para lidar com palavras de parada (stopwords), que são palavras comuns em um idioma\n",
        "from nltk.stem.porter import PorterStemmer  # Biblioteca para aplicar stemming, reduzindo palavras às suas raízes morfológicas\n",
        "import re  # Biblioteca para expressões regulares, usada para manipulação e busca de padrões em strings\n",
        "from tensorflow.keras.models import Sequential  # Biblioteca para criar modelos de redes neurais sequenciais (profundas)\n",
        "from tensorflow.keras.layers import Dense  # Biblioteca para criar camadas densas em redes neurais\n",
        "from sklearn import preprocessing  # Biblioteca para pré-processamento de dados, como padronização e normalização\n",
        "from sklearn.feature_extraction.text import CountVectorizer  # Biblioteca para converter texto em vetores de contagem de palavras\n",
        "from sklearn.model_selection import train_test_split  # Biblioteca para dividir dados em conjuntos de treino e teste\n",
        "import pickle  # Biblioteca para salvar e carregar objetos em formato serializado\n",
        "import numpy as np # Biblioteca para cálculos numéricos\n",
        "\n",
        "# Carregamento dos dados de treinamento, validação e teste\n",
        "treino = pd.read_table('treino.txt', delimiter=';', header=None)\n",
        "validacao = pd.read_table('validacao.txt', delimiter=';', header=None)\n",
        "teste = pd.read_table('teste.txt', delimiter=';', header=None)"
      ],
      "metadata": {
        "id": "pNIi1wgkd57n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenando os conjuntos de dados para facilitar a manipulação\n",
        "dados = pd.concat([treino, validacao, teste])\n",
        "\n",
        "# Definindo os nomes das colunas\n",
        "dados.columns = [\"texto\", \"emocao\"]"
      ],
      "metadata": {
        "id": "Fjj2j8tyd_zm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificando o número de linhas do conjunto de dados\n",
        "print('Número de linhas:', dados.shape[0])\n",
        "\n",
        "# Verificando a quantidade de valores nulos nas linhas\n",
        "print('Valores nulos:', dados.isna().any(axis=1).sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpMXr7s3e-nB",
        "outputId": "1e0a8f90-ce44-4da7-8b6d-231668bb25d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de linhas: 20000\n",
            "Valores nulos: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pré-processamento do texto\n",
        "ps = PorterStemmer()  # Inicializa o stemmer (PorterStemmer) para aplicar stemming\n",
        "\n",
        "def preprocessar(linha):\n",
        "    # Remove caracteres não alfabéticos\n",
        "    revisão = re.sub('[^a-zA-Z]', ' ', linha)\n",
        "    # Converte o texto para minúsculas\n",
        "    revisão = revisão.lower()\n",
        "    # Divide o texto em lista de palavras\n",
        "    revisão = revisão.split()\n",
        "    # Aplica stemming e remove palavras de parada (stopwords)\n",
        "    revisão = [ps.stem(palavra) for palavra in revisão if palavra not in stopwords.words('english')]\n",
        "    # Junta a lista de palavras em uma frase\n",
        "    return \" \".join(revisão)\n",
        "\n",
        "# Aplica o pré-processamento a todos os textos\n",
        "dados['texto'] = dados['texto'].apply(lambda x: preprocessar(x))"
      ],
      "metadata": {
        "id": "JDIWnAxLg5dh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Codificação dos rótulos para valores numéricos\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "dados['emocao_numerica'] = label_encoder.fit_transform(dados['emocao'])\n",
        "\n",
        "# Criação do modelo Bag of Words usando CountVectorizer para converter texto em dados numéricos\n",
        "cv = CountVectorizer(max_features=5000, ngram_range=(1,3))\n",
        "data_cv = cv.fit_transform(dados['texto']).toarray()\n",
        "\n",
        "# Divisão dos dados em treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_cv, dados['emocao_numerica'], test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "LcKEDn8_jRIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializando o modelo sequencial\n",
        "model = Sequential()\n",
        "# Adiciona uma camada densa com 12 neurônios e função de ativação 'relu'\n",
        "model.add(Dense(12, input_shape=(X_train.shape[1],), activation='relu'))\n",
        "# Adiciona uma segunda camada densa com 8 neurônios e função de ativação 'relu'\n",
        "model.add(Dense(8, activation='relu'))\n",
        "# Adiciona uma camada de saída com 6 neurônios (número de classes) e função de ativação 'softmax'\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "\n",
        "# Compila o modelo com função de perda de entropia cruzada categórica e otimizador 'adam'\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Treina o modelo com os dados de treinamento\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=10)\n",
        "\n",
        "# Avalia a precisão do modelo nos dados de treinamento\n",
        "_, accuracy = model.evaluate(X_train, y_train)\n",
        "print(f'Precisão nos dados de treinamento: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Avalia a precisão do modelo nos dados de teste\n",
        "_, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Precisão nos dados de teste: {accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew6VEwprmQHR",
        "outputId": "d3acc51d-d869-4249-bd67-5cc032e0ba55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:86: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.5085 - loss: 1.3203\n",
            "Epoch 2/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9016 - loss: 0.3437\n",
            "Epoch 3/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9573 - loss: 0.1470\n",
            "Epoch 4/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9779 - loss: 0.0793\n",
            "Epoch 5/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9840 - loss: 0.0502\n",
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9887 - loss: 0.0356\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9918 - loss: 0.0269\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9947 - loss: 0.0207\n",
            "Epoch 9/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9951 - loss: 0.0158\n",
            "Epoch 10/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0124\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9967 - loss: 0.0098\n",
            "Precisão nos dados de treinamento: 99.69%\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8691 - loss: 0.7231\n",
            "Precisão nos dados de teste: 85.68%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUvVdnkwdmP1",
        "outputId": "05102f00-5ed2-44cf-a58e-4b33562027da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step\n",
            "sadness\n"
          ]
        }
      ],
      "source": [
        "# Função para prever o rótulo de um novo texto\n",
        "texto = 'I am devasted about the death of my cat'  # Texto a ser previsto\n",
        "texto = preprocessar(texto)  # Pré-processamento do texto\n",
        "array = cv.transform([texto]).toarray()  # Converte o texto para vetor de características\n",
        "pred = model.predict(array)  # Faz a previsão com o modelo\n",
        "a = np.argmax(pred, axis=1)  # Encontra a classe com a maior probabilidade\n",
        "# Exibe o rótulo correspondente ao índice previsto\n",
        "print(label_encoder.inverse_transform(a)[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Salva o modelo em um arquivo .h5\n",
        "model.save('modelo_texto_emocao.h5')\n",
        "\n",
        "# Salva o codificador de rótulos (label encoder) em um arquivo pickle\n",
        "pickle.dump(label_encoder, open('encoder.pkl', 'wb'))\n",
        "\n",
        "# Salva o CountVectorizer em um arquivo pickle\n",
        "pickle.dump(cv, open('CountVectorizer.pkl', 'wb'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D55e6Tamvnd7",
        "outputId": "3bc58d24-b92a-40ec-bb76-6144236c3d3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    }
  ]
}